# Vehicle_Insurance_Fraud_Detection_Final_Project

Contributors:

- Christine Gendron
- Mitchel Diaz
- Steven Dookhantie

## Purpose

Vehicle Insurance Fraud is an expensive, increasingly common, and avoidable problem for insurers. Sophisticated fraud detection processes will be essential to the entire Financial Services Industry moving forward. That’s why this project seeks to use machine learning techniques to understand and predict fraud.

## Questions to Answer

- Can we accurately predict whether an insurance claim is fraudulent?
- Which features are correlated with higher likelihood of fraud?

### Our Data

Our dataset was generated by Angoss KnowledgeSEEKER, a provider of systems for predictive analytics, and found on Kaggle.

This set features over 15,000 claim samples with 33 columns, including information on:

- Demographics of claimant
- Details on the vehicle in question
- Information about the claimants’ policies.
- Whether fraud was detected

[Link to Data](https://www.kaggle.com/datasets/khusheekapoor/vehicle-insurance-fraud-detection)

## Prepping for the Machine Learning Model

- We summarized the dataset using describe(), and identified the column data types using the dtypes attribute.

- We handled missing values using two functions: One to find them, and one using KNNImputer to impute them.

#### Feature Selection and Train_Test_Split

- Some unnecessary columns were dropped after exploratory analysis, including Week of Month, Deductible, AddressChange-Claim, and RepNumber.

- Using a For Loop, we dropped numerical features with a correlation of above 0.8, since those features would make the algorithm more complex without adding significant information.

- The FraudFound column is being used as our target variable, since this is the value we're attempting to predict.

- Data was split into training and testing sets by importing the train_test_split function from sklearn.model_selection, and passing in our target (FraudFound), our features, and a random_state value of 42. These sets are being given the variable names: X_train, X_test, y_train, and y_test.

## Our Machine Learning Model

We have used Logistic Regression to predict fraud. Logistic Regression is not the best algorithm for identifying complex relationships, but our dependent variable (FraudFound) is binary- either fraud was found, or it was not. Logistic Regression is the most efficient algorithm for predicting this type of outcome.

Using Scikit-learn, we created a LogisticRegression() object, then used fit() to train the model using the X_train and y_train sets. Then, we used predict() to return predicted values for FraudFound in our training set (X_test). Using those predicted values and our y_test set, we generated an accuracy score using accuracy_score(). As shown below, our accuracy score is 0.94.

![tts_fit](images/tts_fit.jpg)

![acc_score](images/acc_score.jpg)

## Our Presentation

[View our presentation here.](https://docs.google.com/presentation/d/1seDY3_Q9IZwSew6P-d4DhcwpT5R2ONvDfI21CGmWDHc/edit#slide=id.g14d5c27d989_3_0)

## Our Communication Protocols

We will communicate through Slack messages and on twice-weekly zoom meetings.
